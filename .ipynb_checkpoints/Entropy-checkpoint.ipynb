{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy 的基本精神介紹\n",
    "* 數學家發明了一個公式，用來衡量某一群的資料(分佈)所帶資訊量(亂度)\n",
    "* 相信大家看了上句應該還是很抽像，舉例來說如果我們丟躑兩個特製的銅板(A 銅板及B 銅板)，如果其中一個銅板因為物理構造的原因怎麼出現都是正面，而另一個銅板兩面出現的機率接近 50%，用直覺的想法如果我們要預測 A 銅板的丟躑預測結果所花的心思一定小於 B 銅板，更進一步的說法就是 A 銅板丟躑結果分佈所帶的資訊量(entropy)小於 B 銅板\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Entropy 的計算程式範例\n",
    "底下示範計算某個字串的 entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def entropy(ss = 'gargleblaster'):\n",
    "\n",
    "    ssit = {i for i in ss}\n",
    "\n",
    "    n = len(ss)*1.\n",
    "    entropy = 0\n",
    "\n",
    "    for c in ssit:\n",
    "\n",
    "        p_x = ss.count(c)*1./n\n",
    "\n",
    "        if p_x > 0:\n",
    "\n",
    "            entropy += -(p_x)*math.log(p_x,2)\n",
    "\n",
    "#         print(\"{} {} {}\".format(c,ss.count(c),p_x))\n",
    "#     print(ssit)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.918295834054\n"
     ]
    }
   ],
   "source": [
    "# 丟銅板為例\n",
    "print entropy(\"111111\")\n",
    "print entropy(\"111001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46132014021\n"
     ]
    }
   ],
   "source": [
    "# 也可以計算任何字串\n",
    "print entropy(\"lkejrlejrlewjrlewr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy\n",
    "* 這一篇文章有一個很直觀的介紹 : http://shuokay.com/2017/06/23/cross-entropy/\n",
    "* Y is real data's label(only two labes. e.q. yes or no )\n",
    "* A is your model prediction result , this result is a probability that your model say this test data's label is \"yes\".\n",
    "* 摘錄這篇文章的重要片段如下\n",
    "<img width=\"70%\" src=\"./imgs/Cross_Entropy.png\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array([1,1,0,0,1])\n",
    "A = np.array([0.8, 0.7, 0.2, 0.1, 0.9])\n",
    "A2 = np.array([0.6, 0.6, 0.2, 0.1, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y,A):\n",
    "    m = len(A)\n",
    "    cost = -(1.0/m) * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202736615577\n",
      "0.510825623766\n"
     ]
    }
   ],
   "source": [
    "print cross_entropy(Y,A)\n",
    "print cross_entropy(Y,A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
